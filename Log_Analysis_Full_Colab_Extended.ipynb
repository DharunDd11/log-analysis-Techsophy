{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 1: Install Required Packages\n",
    "!pip install pandas scikit-learn colorama matplotlib openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494a324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 2: Import Required Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from colorama import Fore, Style\n",
    "import time, json, re\n",
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2540e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 3: Upload External Log File (CSV, JSON, .log)\n",
    "uploaded = files.upload()\n",
    "file_name = list(uploaded.keys())[0]\n",
    "print(f\"ðŸ“‚ Uploaded: {file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccb30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 4: Parse Uploaded File Based on Extension\n",
    "def parse_log_file(file_name):\n",
    "    if file_name.endswith('.csv'):\n",
    "        df = pd.read_csv(file_name)\n",
    "    elif file_name.endswith('.json'):\n",
    "        with open(file_name) as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "    elif file_name.endswith('.log'):\n",
    "        logs = []\n",
    "        with open(file_name) as f:\n",
    "            for line in f:\n",
    "                match = re.match(r'^(\\S+ \\S+)\\s+(INFO|WARN|ERROR)\\s+(.*)$', line.strip())\n",
    "                if match:\n",
    "                    logs.append({\n",
    "                        \"timestamp\": match.group(1),\n",
    "                        \"log_level\": match.group(2),\n",
    "                        \"message\": match.group(3)\n",
    "                    })\n",
    "        df = pd.DataFrame(logs)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format\")\n",
    "    return df\n",
    "\n",
    "df = parse_log_file(file_name)\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "if 'time' in df.columns: df = df.rename(columns={'time': 'timestamp'})\n",
    "if 'label' in df.columns: df = df.rename(columns={'label': 'log_level'})\n",
    "if 'content' in df.columns: df = df.rename(columns={'content': 'message'})\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "df = df.dropna(subset=['timestamp'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a64bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 5: Feature Extraction\n",
    "def extract_features(df):\n",
    "    df['error'] = df['log_level'].astype(str).apply(lambda x: 1 if 'ERROR' in x else 0)\n",
    "    df['warn'] = df['log_level'].astype(str).apply(lambda x: 1 if 'WARN' in x else 0)\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "    return df[['error', 'warn', 'minute']]\n",
    "\n",
    "features = extract_features(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72b6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 6: Anomaly Detection\n",
    "model = IsolationForest(contamination=0.2, random_state=42)\n",
    "model.fit(features)\n",
    "df['incident'] = model.predict(features).tolist()\n",
    "df['incident'] = df['incident'].apply(lambda x: 1 if x == -1 else 0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653f3822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 7: Alerting with Alert Fatigue Handling\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "\n",
    "alert_memory = defaultdict(int)\n",
    "last_alert_minute = defaultdict(lambda: -99)\n",
    "\n",
    "def hash_message(msg):\n",
    "    return hashlib.md5(msg.encode()).hexdigest()\n",
    "\n",
    "def send_fatigue_alerts(df, cooldown=2):\n",
    "    for _, row in df.iterrows():\n",
    "        if row['incident']:\n",
    "            key = hash_message(row['message'])\n",
    "            current_minute = row['timestamp'].minute\n",
    "            if current_minute - last_alert_minute[key] >= cooldown:\n",
    "                print(f\"{Fore.RED}[ALERT] {row['timestamp']} | {row['message']}{Style.RESET_ALL}\")\n",
    "                last_alert_minute[key] = current_minute\n",
    "\n",
    "send_fatigue_alerts(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89684df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 8: Export Detected Alerts\n",
    "alerts = df[df['incident'] == 1]\n",
    "alerts.to_csv(\"alerts.csv\", index=False)\n",
    "alerts.to_excel(\"alerts.xlsx\", index=False)\n",
    "print(\"âœ… Exported alerts to alerts.csv and alerts.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c1586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 9: Plot Incidents Over Time\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['timestamp'], df['incident'], marker='o', linestyle='-')\n",
    "plt.title(\"Incident Prediction Over Time\")\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Incident (1=Yes, 0=No)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb38cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“˜ Step 10: Real-Time Simulation with Fatigue Handling\n",
    "def simulate_real_time(df, delay=1, cooldown=2):\n",
    "    print(\"\\nðŸ” Real-time Simulation Starting...\\n\")\n",
    "    model = IsolationForest(contamination=0.2, random_state=42)\n",
    "    fatigue_tracker = defaultdict(lambda: -99)\n",
    "\n",
    "    for i in range(3, len(df)+1):\n",
    "        batch = df.iloc[:i].copy()\n",
    "        feats = extract_features(batch)\n",
    "        model.fit(feats)\n",
    "        batch['incident'] = model.predict(feats)\n",
    "        batch['incident'] = batch['incident'].apply(lambda x: 1 if x == -1 else 0)\n",
    "        latest = batch.iloc[-1]\n",
    "        key = hash_message(latest['message'])\n",
    "        minute = latest['timestamp'].minute\n",
    "        if latest['incident'] and (minute - fatigue_tracker[key] >= cooldown):\n",
    "            print(f\"{Fore.RED}[REAL-TIME ALERT] {latest['timestamp']} | {latest['message']}{Style.RESET_ALL}\")\n",
    "            fatigue_tracker[key] = minute\n",
    "        else:\n",
    "            print(f\"[OK] {latest['timestamp']} | {latest['message']}\")\n",
    "        time.sleep(delay)\n",
    "\n",
    "simulate_real_time(df, delay=1)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
